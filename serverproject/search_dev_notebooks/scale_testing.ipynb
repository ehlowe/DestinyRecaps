{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DestinyFolder\\DestinyRecaps\\DestinyRecapsApi\\serverproject\n"
     ]
    }
   ],
   "source": [
    "# DIRECTORY SET\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "base_dir=Path(os.getcwd()).parent\n",
    "# os.chdir(os.path.join(base_dir, 'serverproject'))\n",
    "os.chdir(base_dir)\n",
    "print(os.getcwd())\n",
    "\n",
    "# Load dotenv\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# DJANGO SETUP\n",
    "import django\n",
    "sys.path.append(os.path.abspath(''))\n",
    "os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"serverproject.settings\")\n",
    "django.setup()\n",
    "\n",
    "# Import async modules\n",
    "import asyncio\n",
    "from asgiref.sync import sync_to_async\n",
    "\n",
    "# Import display modules\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Import other modules\n",
    "import faiss\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from destinyapp.models import StreamRecapData, FastRecapData\n",
    "\n",
    "from core import services\n",
    "from core import utils\n",
    "from core import controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"text-embedding-3-large\"\n",
    "\n",
    "async def fetch_embedding(chunk):\n",
    "    # Simulate an async call to the embeddings API\n",
    "    #return await asyncio.to_thread(openai_client.embeddings.create, input=chunk, model=model)\n",
    "    model=\"text-embedding-3-large\"        \n",
    "\n",
    "    fails=0\n",
    "    while fails<5:\n",
    "        try:\n",
    "            return await utils.async_openai_client.embeddings.create(input=chunk, model=model)\n",
    "        except Exception as e:\n",
    "            fails+=1\n",
    "            print(\"Emedding Fail Retrying:\",e)\n",
    "            await asyncio.sleep(10+(fails*2))\n",
    "    return None\n",
    "\n",
    "async def generate_embeddings_async(text_chunks, model):\n",
    "\n",
    "    responses = await asyncio.gather(*(fetch_embedding(chunk) for chunk in text_chunks))\n",
    "    embeddings = [response.data[0].embedding for response in responses]\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\DestinyFolder\\DestinyRecaps\\DestinyRecapsApi\\serverproject\n",
      "d:\\DestinyFolder\\DestinyRecaps\\DestinyRecapsApi\\serverproject\\search_dev_notebooks\\working\\indexes\n",
      "True\n",
      "d:\\DestinyFolder\\DestinyRecaps\\DestinyRecapsApi\\serverproject\\search_dev_notebooks\\working\\indexes\\scale\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "indexes_path=os.path.join(os.getcwd(),\"search_dev_notebooks\",\"working\",\"indexes\")\n",
    "\n",
    "print(indexes_path)\n",
    "print(os.path.isdir(indexes_path))\n",
    "\n",
    "scale_path=os.path.join(indexes_path,\"scale\")\n",
    "print(scale_path)\n",
    "print(os.path.isdir(scale_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# larger index creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=await fetch_embedding(\"get embedding size\")\n",
    "embedding_size=len(embedding.data[0].embedding)\n",
    "vector_db=faiss.IndexFlatL2(embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bigger faiss index\n",
    "texts=[\"This is a test\", \"The quick brown fox jumps over the lazy dog\", \"I love eating pizza on rainy days\", \"Machine learning is fascinating\", \"The sunset painted the sky in brilliant colors\", \"She danced through fields of wildflowers\", \"The old library held countless untold stories\", \"Coffee is essential for Monday mornings\", \"Waves crashed against the rocky shore\", \"Dragons soared through cloudy skies\"]\n",
    "embeddings=await generate_embeddings_async(texts, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db.add(np.array(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the index to a file\n",
    "faiss.write_index(vector_db, os.path.join(indexes_path, \"test_index.faiss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the index from a file\n",
    "vector_db=faiss.read_index(os.path.join(indexes_path, \"test_index.faiss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the index\n",
    "query_text=\"This is a test\"\n",
    "query_embedding=await fetch_embedding(query_text)\n",
    "query_embedding_np = np.array(query_embedding.data[0].embedding).astype('float32').reshape(1, -1)\n",
    "k_size=5\n",
    "k=vector_db.ntotal\n",
    "if k>k_size:\n",
    "    k=k_size\n",
    "\n",
    "D, I = vector_db.search(query_embedding_np, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[2.1857386e-06 1.1849377e+00 1.6127548e+00 1.6167562e+00 1.6696446e+00]]\n",
      "I: [[0 1 3 7 8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"D:\",D)\n",
    "print(\"I:\",I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.asarray(query_embedding.data[0].embedding)\n",
    "embedding_matrix = np.asarray(embeddings)\n",
    "\n",
    "# Reshape query to 1D if needed\n",
    "if len(query.shape) > 1:\n",
    "    query = query.reshape(-1)\n",
    "    \n",
    "# Calculate euclidean distances using broadcasting\n",
    "# This is more efficient than looping\n",
    "distances = np.sqrt(np.sum((embedding_matrix - query) ** 2, axis=1))\n",
    "\n",
    "# Get indices of k smallest distances\n",
    "nearest_indices = np.argsort(distances)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00147842, 1.08854847, 1.34954656, 1.26994282, 1.33518695,\n",
       "       1.34190124, 1.35120326, 1.27151728, 1.29214726, 1.29558511])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nearest_indices: [0 1 3 7 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"nearest_indices:\",nearest_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finish of larger index creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCALE CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_videos=[]\n",
    "for i in range(100):\n",
    "    test_videos.append(f\"{i}\")\n",
    "\n",
    "\n",
    "json_embeddings={}\n",
    "\n",
    "for test_video in test_videos:\n",
    "    texts=[\"This is a test\", \"The quick brown fox jumps over the lazy dog\", \"I love eating pizza on rainy days\", \"Machine learning is fascinating\", \"The sunset painted the sky in brilliant colors\", \"She danced through fields of wildflowers\", \"The old library held countless untold stories\", \"Coffee is essential for Monday mornings\", \"Waves crashed against the rocky shore\", \"Dragons soared through cloudy skies\"]\n",
    "    embeddings=await generate_embeddings_async(texts, model)\n",
    "    json_embeddings[test_video]=embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "with open(os.path.join(scale_path,\"json_embeddings_big.json\"), \"w\") as f:\n",
    "    json.dump(json_embeddings, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings=list(json_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Time taken: 0.0010077953338623047\n"
     ]
    }
   ],
   "source": [
    "t_start=time.time()\n",
    "item, index=find_nth_item(all_embeddings, 11)\n",
    "print(index)    \n",
    "t_end=time.time()\n",
    "print(\"Time taken:\",t_end-t_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nth_item(nested_array, n):\n",
    "    \"\"\"\n",
    "    Find the nth item (0-based index) in a nested array and return the item and its group index.\n",
    "    \n",
    "    Args:\n",
    "        nested_array: List of lists containing numbers\n",
    "        n: The index to find (0-based)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (item, group_index) or None if n is out of range\n",
    "    \"\"\"\n",
    "    current_index = 0\n",
    "    \n",
    "    for group_index, group in enumerate(nested_array):\n",
    "        if current_index + len(group) > n:\n",
    "            # The item is in this group\n",
    "            item_index = n - current_index\n",
    "            return (group[item_index], group_index)\n",
    "        current_index += len(group)\n",
    "    \n",
    "    return None  # n is out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from file\n",
    "with open(os.path.join(scale_path,\"json_embeddings_big.json\"), \"r\") as f:\n",
    "    json_embeddings=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings=list(json_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_np=[]\n",
    "for embeddings in all_embeddings:\n",
    "    for embedding in embeddings:\n",
    "        embeddings_np.append(np.array(embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"This is a test\"\n",
    "k_size=5\n",
    "query_embedding=await fetch_embedding(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.asarray(query_embedding.data[0].embedding)\n",
    "embedding_matrix = np.asarray(embeddings_np)\n",
    "\n",
    "# Reshape query to 1D if needed\n",
    "if len(query.shape) > 1:\n",
    "    query = query.reshape(-1)\n",
    "    \n",
    "# Calculate euclidean distances using broadcasting\n",
    "# This is more efficient than looping\n",
    "distances = np.sqrt(np.sum((embedding_matrix - query) ** 2, axis=1))\n",
    "\n",
    "# Get indices of k smallest distances\n",
    "k=len(embeddings_np)\n",
    "if k>k_size:\n",
    "    k=k_size\n",
    "nearest_indices = np.argsort(distances)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(embeddings_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([690, 390, 450, 250, 460], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
